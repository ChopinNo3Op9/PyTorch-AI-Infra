{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import models, resnet18\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=16, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# Load pre-trained ResNet-18 model\n",
    "model = resnet18(pretrained=False, num_classes=10).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Training function\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(enumerate(trainloader), total=len(trainloader))\n",
    "    for batch_idx, (inputs, targets) in pbar:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_description(f'Epoch {epoch+1}, Loss: {running_loss/(batch_idx+1):.4f}')\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 1\n",
    "\n",
    "# Profile training loop\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    for epoch in range(num_epochs):\n",
    "        train(epoch)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "# Test the network\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a synthetic dataset\n",
    "batch_size = 32\n",
    "num_samples = 1000\n",
    "input_size = (3, 224, 224)  # Typical input size for ResNet18\n",
    "\n",
    "# Generate random data\n",
    "inputs = torch.randn(num_samples, *input_size)\n",
    "targets = torch.randint(0, 1000, (num_samples,))  # Assuming 1000 classes\n",
    "\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize ResNet18 model\n",
    "model = models.resnet18(pretrained=False)\n",
    "model.train()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_with_profiler(dataloader, model, criterion, optimizer):\n",
    "    # with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "    #              schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=1),\n",
    "    #              on_trace_ready=torch.profiler.tensorboard_trace_handler('./logs'),\n",
    "    #              record_shapes=True, \n",
    "    #              profile_memory=True, \n",
    "    #              with_stack=True) as prof:\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], \n",
    "             record_shapes=True, \n",
    "             profile_memory=True, \n",
    "             with_stack=True) as prof:\n",
    "    # Your training loop or workload here\n",
    "    # Remember to call prof.step() appropriately\n",
    "        for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            prof.step()  # Inform the profiler that one step has finished.\n",
    "            \n",
    "            if batch_idx == 5:  # For demonstration, we only run a few batches.\n",
    "                break\n",
    "\n",
    "train_with_profiler(dataloader, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=./logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
