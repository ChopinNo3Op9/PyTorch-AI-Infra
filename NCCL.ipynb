{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.distributed as dist\n",
    "import os\n",
    "import argparse\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# Argument parser for easily running script from the command line\n",
    "parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training with DDP')\n",
    "parser.add_argument('--local_rank', default=-1, type=int,\n",
    "                    help='node rank for distributed training')\n",
    "\n",
    "def main():\n",
    "    args = parser.parse_args()\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    dist.init_process_group(backend='nccl')  # communication backends\n",
    "\n",
    "    # Data loading and normalization\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(trainset)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                              shuffle=False, num_workers=2, sampler=train_sampler)\n",
    "\n",
    "    # CNN architecture\n",
    "    class Net(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Net, self).__init__()\n",
    "            # takes an input with 3 channels (e.g., RGB images) and produces 6 output channels using 6 convolutional filters, each with a kernel size of 5x5.\n",
    "            self.conv1 = nn.Conv2d(3, 6, 5)  # in_channels, out_channels, kernel_size (small matrix used for the convolution operation)\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "            self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "            self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "            self.fc2 = nn.Linear(120, 84)\n",
    "            self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.pool(F.relu(self.conv1(x)))\n",
    "            x = self.pool(F.relu(self.conv2(x)))\n",
    "            x = x.view(-1, 16 * 5 * 5) # reshapes the output tensor x from the convolutional and pooling layers into a 1-dimensional tensor, prepares for processing by fully connected layers\n",
    "            x = F.relu(self.fc1(x))\n",
    "            x = F.relu(self.fc2(x))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    net = Net().cuda()\n",
    "    net = DDP(net, device_ids=[args.local_rank], output_device=args.local_rank)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m torch.distributed.launch --nproc_per_node=4 train_script.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
